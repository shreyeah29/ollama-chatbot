# Ollama Chatbot 🤖

A locally hosted AI chatbot that integrates multiple open-source LLMs using [Ollama](https://ollama.ai/).  
Built with Flask and a lightweight frontend, the chatbot supports **multi-model conversations**, **real-time interaction**, and **privacy-preserving local execution**.

---

## ✨ Features
- 🔀 **Multi-Model Support**: Integrates models like `llama3.2`, `phi`, `tinyllama`, and `neural-chat`.  
- 🧠 **Model Choice Prediction (MCP)**: Dynamically selects the most suitable model based on query type.  
- 💬 **Real-Time Chat**: Instant responses with typing indicators and history persistence.  
- 🌐 **Web Interface**: Simple frontend with chat UI built using HTML, CSS, and JavaScript.  
- 🔒 **Privacy-Preserving**: All models run locally through Ollama, ensuring data security.  

---

## 🛠️ Tech Stack
- **Backend**: Python, Flask, Flask-CORS, requests, pytz  
- **Frontend**: HTML, CSS, JavaScript (static & templates)  
- **LLM Integration**: Ollama CLI (runs locally)  
- **Deployment**: Docker & Docker Compose (optional)  


